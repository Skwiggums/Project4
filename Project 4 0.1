import sys
import random
import numpy as np
import pandas as pd
import glob
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras import layers
from tensorflow.keras import optimizers
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

#a='he didnâ€™t notice that the lights had changed\n'
#b=a.encode('utf-8','replace')

class networks:
    def __init__(self,):
        print('init')
    def maketrain(self,filename,winsize,stride,outname):#task 1
        self.filename=filename
        self.winsize=winsize
        self.stride=stride
        self.outname=outname

        ##reading in file
        data=open(self.filename,'r').readlines()
        chardata=open(self.filename,'r').read()
        chars=list(set(chardata))
        lines,char_size,vocab_size=len(data),len(chardata),len(chars)#lines is amount of sequences
        print ('data has {} lines, {} characters, {} unique characters'.format(lines,char_size, vocab_size))

        ## creating output file
        # using modified code from https://stackoverflow.com/questions/41373371/moving-window-in-numpy-with-dynamic-stride-and-window-size?noredirect=1&lq=1
        output=[]#size starts unitialized
        for i in range(lines):
            parse=data[i]
            parse=parse[:-1]#removing new line symbol
            for index in range(0,len(parse)-self.winsize,self.stride):
                outstring=parse[index:index+self.winsize+1]+'\n'
                outstring=str(outstring.encode("ascii", "ignore"),'utf-8')#removing all non-ascii characters, reading in the texts produces some wonkiness
                output.append(outstring)
                print(outstring)
        outfile=open(self.outname,'w+')
        outfile.writelines(output)
        outfile.close()
        return output

    def makearray(self,filename):#task 2
        self.filename=filename
        infile=open(self.filename,'r').readlines()
        alphabet=open(self.filename,'r').read()
        alphabet=alphabet.replace('\n','')#removing new line symbol
        infile=np.array(infile)
        m=len(infile)#number of sequences
        n=len(infile[0])-1#sequence length minus 1 to account for newline
        p=len(list(set(alphabet)))#amount of unique characters
        alphabet=list(set(alphabet))#all characters in training data
        inputarray=np.zeros((m,n,p))#one-hot encoded input array

        ##one-hot encoding using code from here:https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/
        char_to_int = dict((c, i) for i, c in enumerate(alphabet))
        int_to_char = dict((i, c) for i, c in enumerate(alphabet))
        for i in range(0,m):
            sequence=infile[i][0:n]
            integerencode=[char_to_int[char] for char in sequence]#cuts off newline symbol
            inputarray[i,:,:]=to_categorical(integerencode,num_classes=p)

    def predict(self,modelname,winsize,initchar,qi,char2make):#task 3
        self.modelname
        self.winsize
        self.initchar
        self.qi
        self.char2make

    def trainmodel(self,model,traindata,epochs=10,lr=0.1,lrfactor=0.2,mom=0.1):#task 4
        self.model
        self.traindata
        self.epochs
        self.lr
        self.lrfactor
        self.mom
    

## 8 network comparison results #tasks 5 and 6, testing for now.
NETWORKS=networks()
trainingdata=NETWORKS.maketrain('beatles.txt',5,3,'trainingdata.txt')
arrays=NETWORKS.makearray('trainingdata.txt')
